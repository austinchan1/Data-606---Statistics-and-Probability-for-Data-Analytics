---
title: "Homework 3"
author: "Austin Chan"
date: "February 27, 2019"
output: html_document
---


##3.2

###a).

```{r}
pnorm(-1.13, mean = 0, sd = 1, lower.tail = FALSE)
```

```{r}
# draw the normal curve
curve(dnorm(x,0,1), xlim=c(-3,3), main="Normal density")
 
# define shaded region
from.z <- -1.13
to.z <- 3
 
S.x  <- c(from.z, seq(from.z, to.z, 0.01), to.z)
S.y  <- c(0, dnorm(seq(from.z, to.z, 0.01)), 0)
polygon(S.x,S.y, col="red")
```

###b).


```{r}
pnorm(0.18, mean = 0, sd = 1)
```

```{r}
# draw the normal curve
curve(dnorm(x,0,1), xlim=c(-3,3), main="Normal density")
 
# define shaded region
from.z <- -3
to.z <- 0.18
 
S.x  <- c(from.z, seq(from.z, to.z, 0.01), to.z)
S.y  <- c(0, dnorm(seq(from.z, to.z, 0.01)), 0)
polygon(S.x,S.y, col="red")
```

###c).

The area is incredibly small. It is basically zero.

```{r}
pnorm(8, mean = 0, sd = 1, lower.tail = FALSE)
```

```{r}
# draw the normal curve
curve(dnorm(x,0,1), xlim=c(-9,9), main="Normal density")
 
# define shaded region
from.z <- 8
to.z <- 9
 
S.x  <- c(from.z, seq(from.z, to.z, 0.01), to.z)
S.y  <- c(0, dnorm(seq(from.z, to.z, 0.01)), 0)
polygon(S.x,S.y, col="red")
```

###d).

```{r}
pnorm(0.5, mean = 0, sd = 1) - pnorm(-0.5, mean = 0, sd = 1)
```

```{r}
# draw the normal curve
curve(dnorm(x,0,1), xlim=c(-3,3), main="Normal density")
 
# define shaded region
from.z <- -0.5
to.z <- 0.5
 
S.x  <- c(from.z, seq(from.z, to.z, 0.01), to.z)
S.y  <- c(0, dnorm(seq(from.z, to.z, 0.01)), 0)
polygon(S.x,S.y, col="red")
```

##3.4

###a).

Men, Ages 30 - 34 ~ N(Mean = 4313, Standard Deviation = 583)

Women, Ages 25 - 29 ~ N(Mean = 5261, Standard Deviation = 807)

###b).

Leo's Z-score:

```{r}
(4948 - 4313)/583
```

Mary's Z-score:

```{r}
(5513 - 5261)/807
```

The Z-scores tell us the number of standard deviations away from the mean that each participant performed relative to their competition groupings.


###c).

Relative to their respective populations, Mary had a better finishing time than Leo because she was only 0.3 standard deviations above the mean compared to Leo who was 1.09 standard deviations above the mean. While Leo was faster in an absolute sense, Mary was faster in a relative sense.

###d).

Since larger times are worse, I set lower.tail to false to capture the percentage of people who had a longer time than Leo.

```{r}
pnorm(4948, mean = 4313, sd = 583, lower.tail = FALSE)
```

###e).

```{r}
pnorm(5513, mean = 5261, sd = 807, lower.tail = FALSE)
```

###f).

If the distribution of finishing times was not nearly normal, then we could not compare the times using Z-scores. Since Z-scores depend on the assumption that the data is distributed normally, Z-scores cannot be compared when the data is not normal. The answers to parts b - e would change because they would require different distribution calculations in order to compare the two athletes.


##3.18

###a).

```{r}
heights = c(54,55,56,56,57,58,58,59,60,60,60,61,61,62,62,63,63,63,64,65,65,67,67,69,73)

heightMean = 61.52
heightSD = 4.58
```

One standard deviation:

```{r}
length(heights[heights > heightMean - heightSD & heights < heightMean + heightSD])/length(heights)
```

Two standard deviations:

```{r}
length(heights[heights > heightMean - (2*heightSD) & heights < heightMean + (2*heightSD)])/length(heights)
```

Three standard deviations:

```{r}
length(heights[heights > heightMean - (3*heightSD) & heights < heightMean + (3*heightSD)])/length(heights)
```

The heights follow the rule very well.

###b).

The data does appear to follow a normal distribution, but is very slightly skewed to the right. The spread of the data fits mostly under the ideal distribution line, however the 55-60 bin appears to be over the line while the 65-70 bin is under the line. The points on the QQ plot are mostly on the line, however, there is a very slight upward curve, which would indicate a very slight right skew.

##3.22

###a).

```{r}
(0.98^9) * (0.02)
```

###b).

```{r}
0.98^100
```

###c).

Expected number of transistors produced before first defect:

```{r}
1/0.02
```

Standard deviation:

```{r}
sqrt(0.02 * (1- 0.02))
```

###d).

Expected number of transistors produced before first defect:

```{r}
1/0.05
```

Standard deviation:

```{r}
sqrt(0.05 * (1- 0.05))
```

###e).

As the probability of the event occurring increases, the expected number of trials before the first event decreases and the standard deviation increases.

##3.38

###a).

```{r}
dbinom(2, 3,0.51)
```

###b).

{B,B,G}, {B,G,B}, {G,B,B}

```{r}
#Probability of 2 boys, one girl times 3 permutations of 2 boys, one girl:
(3) * (0.51^2) * (0.49)
```

###c).

If we used approach (b) for 3 boys from 8 kids, we would have to list all of the permutations of 3 boys from 8 kids. 3 choose 8 is 56, so there would need to be 56 different permutations that would need to be listed. The part (a) approach is straightforward because it uses a formula instead of counting permutations and their probabilities manually.

##3.42

###a).

```{r}
choose(10-1,3-1) * (0.15^3) * ((1-0.15)^(10-3))
```

###b).

0.15, since the probability of success for each trial is independent.

###c).

Part (a) asks for the probability of the 3rd successful serve on the 10th attempt. In order to get to the 10th attempt to calculate this probability, we need to calculate the probability of getting 2 successes in 9 attempts and then multiply it by the probability of succeeding on the 10th attempt. This part does not assume that 9 attempts were already made, like part (b).

Part (b) asks for the probability that the 10th serve will be successful given that the previous 9 attempts had 2 successful serves. Since each serve is independent, it doesn't matter what happened in the previous 9 serves. The probability of each individual serve is always 0.15.













